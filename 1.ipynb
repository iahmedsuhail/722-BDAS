{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('1').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing data.\n",
    "df = spark.read.csv('dataset/ri_statewide_2019_02_25.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------+----+------------+-----------+-------------+---------+-----------+---------------+--------------+--------+----------------+----------------+------------------+------------------+----------------+---------------+----------------+------------+-----------------+--------------------+------------+-------------+\n",
      "|raw_row_number|      date|    time|zone|subject_race|subject_sex|department_id|     type|arrest_made|citation_issued|warning_issued| outcome|contraband_found|contraband_drugs|contraband_weapons|contraband_alcohol|contraband_other|frisk_performed|search_conducted|search_basis|reason_for_search|     reason_for_stop|vehicle_make|vehicle_model|\n",
      "+--------------+----------+--------+----+------------+-----------+-------------+---------+-----------+---------------+--------------+--------+----------------+----------------+------------------+------------------+----------------+---------------+----------------+------------+-----------------+--------------------+------------+-------------+\n",
      "|             1|2005-11-22|11:15:00|  X3|       white|       male|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|             2|2005-10-01|12:20:00|  X3|       white|       male|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|             3|2005-10-01|12:30:00|  X3|       white|     female|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|             4|2005-10-01|12:50:00|  X3|       white|       male|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|             5|2005-10-01|13:10:00|  X3|       white|     female|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|             6|2005-10-01|15:50:00|  X3|       white|       male|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|Other Traffic Vio...|          NA|           NA|\n",
      "|             7|2005-09-11|11:45:00|  X3|       white|       male|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|             8|2005-09-11|11:45:00|  X3|       white|     female|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|             9|2005-10-04|11:55:00|  X3|    hispanic|       male|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|            10|2005-10-04|11:55:00|  X3|       white|       male|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|            11|2005-10-04|14:28:00|  X3|       white|     female|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|            12|2005-10-04|14:45:00|  X3|       white|       male|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|            13|2005-10-04|15:02:00|  X3|       white|       male|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|            14|2005-10-04|15:35:00|  X3|       white|       male|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|            15|2005-10-10|17:50:00|  X3|       white|       male|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|Other Traffic Vio...|          NA|           NA|\n",
      "|            16|2005-10-10|18:10:00|  X3|       white|     female|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|Other Traffic Vio...|          NA|           NA|\n",
      "|            17|2005-10-10|18:35:00|  X3|       white|       male|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|            18|2005-10-10|19:20:00|  X3|       white|     female|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|            19|2005-10-17|11:55:00|  X3|       white|     female|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "|            20|2005-10-17|14:10:00|  X3|       white|     female|          200|vehicular|      FALSE|           TRUE|         FALSE|citation|              NA|              NA|                NA|                NA|           false|          FALSE|           FALSE|          NA|               NA|            Speeding|          NA|           NA|\n",
      "+--------------+----------+--------+----+------------+-----------+-------------+---------+-----------+---------------+--------------+--------+----------------+----------------+------------------+------------------+----------------+---------------+----------------+------------+-----------------+--------------------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Intial look at the data\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- raw_row_number: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- subject_race: string (nullable = true)\n",
      " |-- subject_sex: string (nullable = true)\n",
      " |-- department_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- arrest_made: string (nullable = true)\n",
      " |-- citation_issued: string (nullable = true)\n",
      " |-- warning_issued: string (nullable = true)\n",
      " |-- outcome: string (nullable = true)\n",
      " |-- contraband_found: string (nullable = true)\n",
      " |-- contraband_drugs: string (nullable = true)\n",
      " |-- contraband_weapons: string (nullable = true)\n",
      " |-- contraband_alcohol: string (nullable = true)\n",
      " |-- contraband_other: boolean (nullable = true)\n",
      " |-- frisk_performed: string (nullable = true)\n",
      " |-- search_conducted: string (nullable = true)\n",
      " |-- search_basis: string (nullable = true)\n",
      " |-- reason_for_search: string (nullable = true)\n",
      " |-- reason_for_stop: string (nullable = true)\n",
      " |-- vehicle_make: string (nullable = true)\n",
      " |-- vehicle_model: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Print the schema\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "509681"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total number of values\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|subject_sex| count|\n",
      "+-----------+------+\n",
      "|         NA| 29097|\n",
      "|     female|131138|\n",
      "|       male|349446|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"subject_sex\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------+-----+\n",
      "|zone|subject_sex|count|\n",
      "+----+-----------+-----+\n",
      "|  X3|     female|26653|\n",
      "|  X3|         NA| 4627|\n",
      "|  X3|       male|62778|\n",
      "|  X4|         NA| 9679|\n",
      "|  X4|       male|94953|\n",
      "|  K3|     female|29097|\n",
      "|  X1|         NA| 3491|\n",
      "|  X1|     female| 2702|\n",
      "|  K3|       male|79771|\n",
      "|  X1|       male|10522|\n",
      "|  K1|         NA| 2252|\n",
      "|  K2|     female|28114|\n",
      "|  K1|       male|32255|\n",
      "|  NA|         NA|   10|\n",
      "|  K3|         NA| 4916|\n",
      "|  K1|     female|13855|\n",
      "|  K2|         NA| 4122|\n",
      "|  X4|     female|30717|\n",
      "|  K2|       male|69167|\n",
      "+----+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy([\"zone\", \"subject_sex\"]).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------------+------+\n",
      "|subject_sex|     reason_for_stop| count|\n",
      "+-----------+--------------------+------+\n",
      "|     female|Other Traffic Vio...| 17911|\n",
      "|       male|Special Detail/Di...| 12977|\n",
      "|     female|Equipment/Inspect...| 14039|\n",
      "|     female|                 APB|   109|\n",
      "|     female|Violation of City...|   216|\n",
      "|         NA|    Call for Service|     4|\n",
      "|         NA|Equipment/Inspect...|     2|\n",
      "|       male|    Call for Service|  5237|\n",
      "|       male|Registration Viol...| 14181|\n",
      "|       male|            Speeding|182538|\n",
      "|         NA|            Speeding|     8|\n",
      "|       male|Motorist Assist/C...|   657|\n",
      "|       male|   Suspicious Person|   268|\n",
      "|     female|  Seatbelt Violation|  3550|\n",
      "|     female|Registration Viol...|  5649|\n",
      "|       male|Other Traffic Vio...| 72317|\n",
      "|         NA|                  NA| 29073|\n",
      "|     female|   Suspicious Person|    74|\n",
      "|         NA|  Seatbelt Violation|     3|\n",
      "|       male|                 APB|   376|\n",
      "+-----------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy([\"subject_sex\", \"reason_for_stop\"]).count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the rows from which subject_sex is missing\n",
    "#Regular dropna wasn't working cuz data is a String \"NA\"\n",
    "df = df.filter(df.subject_sex.endswith('ale'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+\n",
      "|subject_sex| count|\n",
      "+-----------+------+\n",
      "|     female|131138|\n",
      "|       male|349446|\n",
      "+-----------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"subject_sex\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|contraband_found| count|\n",
      "+----------------+------+\n",
      "|           FALSE| 11183|\n",
      "|              NA|462822|\n",
      "|            TRUE|  6579|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"contraband_found\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480584"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total number of values in data BEFORE dropping duplicates\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicates from data\n",
    "df = df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480584"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total number of values in data AFTER dropping duplicates\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- raw_row_number: integer (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- subject_race: string (nullable = true)\n",
      " |-- subject_sex: string (nullable = true)\n",
      " |-- department_id: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- arrest_made: string (nullable = true)\n",
      " |-- citation_issued: string (nullable = true)\n",
      " |-- warning_issued: string (nullable = true)\n",
      " |-- outcome: string (nullable = true)\n",
      " |-- contraband_found: string (nullable = true)\n",
      " |-- contraband_drugs: string (nullable = true)\n",
      " |-- contraband_weapons: string (nullable = true)\n",
      " |-- contraband_alcohol: string (nullable = true)\n",
      " |-- contraband_other: boolean (nullable = true)\n",
      " |-- frisk_performed: string (nullable = true)\n",
      " |-- search_conducted: string (nullable = true)\n",
      " |-- search_basis: string (nullable = true)\n",
      " |-- reason_for_search: string (nullable = true)\n",
      " |-- reason_for_stop: string (nullable = true)\n",
      " |-- vehicle_make: string (nullable = true)\n",
      " |-- vehicle_model: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For checking what to drop\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Prim keys from data\n",
    "df = df.drop(\"raw_row_number\", \"department_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- subject_race: string (nullable = true)\n",
      " |-- subject_sex: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- arrest_made: string (nullable = true)\n",
      " |-- citation_issued: string (nullable = true)\n",
      " |-- warning_issued: string (nullable = true)\n",
      " |-- outcome: string (nullable = true)\n",
      " |-- contraband_found: string (nullable = true)\n",
      " |-- contraband_drugs: string (nullable = true)\n",
      " |-- contraband_weapons: string (nullable = true)\n",
      " |-- contraband_alcohol: string (nullable = true)\n",
      " |-- contraband_other: boolean (nullable = true)\n",
      " |-- frisk_performed: string (nullable = true)\n",
      " |-- search_conducted: string (nullable = true)\n",
      " |-- search_basis: string (nullable = true)\n",
      " |-- reason_for_search: string (nullable = true)\n",
      " |-- reason_for_stop: string (nullable = true)\n",
      " |-- vehicle_make: string (nullable = true)\n",
      " |-- vehicle_model: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n",
      "|     type| count|\n",
      "+---------+------+\n",
      "|vehicular|480584|\n",
      "+---------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check feature type\n",
    "df.groupBy(\"type\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop type feature from data, since it has only one value\n",
    "df = df.drop('type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- subject_race: string (nullable = true)\n",
      " |-- subject_sex: string (nullable = true)\n",
      " |-- arrest_made: string (nullable = true)\n",
      " |-- citation_issued: string (nullable = true)\n",
      " |-- warning_issued: string (nullable = true)\n",
      " |-- outcome: string (nullable = true)\n",
      " |-- contraband_found: string (nullable = true)\n",
      " |-- contraband_drugs: string (nullable = true)\n",
      " |-- contraband_weapons: string (nullable = true)\n",
      " |-- contraband_alcohol: string (nullable = true)\n",
      " |-- contraband_other: boolean (nullable = true)\n",
      " |-- frisk_performed: string (nullable = true)\n",
      " |-- search_conducted: string (nullable = true)\n",
      " |-- search_basis: string (nullable = true)\n",
      " |-- reason_for_search: string (nullable = true)\n",
      " |-- reason_for_stop: string (nullable = true)\n",
      " |-- vehicle_make: string (nullable = true)\n",
      " |-- vehicle_model: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking if type was dropped\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|        subject_race| count|\n",
      "+--------------------+------+\n",
      "|               white|344716|\n",
      "|               black| 68577|\n",
      "|            hispanic| 53123|\n",
      "|       other/unknown|  1344|\n",
      "|asian/pacific isl...| 12824|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy(\"subject_race\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|search_conducted| count|\n",
      "+----------------+------+\n",
      "|           FALSE|462822|\n",
      "|            TRUE| 17762|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NA Values in some fields\n",
    "df.groupBy(\"search_conducted\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|contraband_found| count|\n",
      "+----------------+------+\n",
      "|           FALSE| 11183|\n",
      "|              NA|462822|\n",
      "|            TRUE|  6579|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NA Values in some fields\n",
    "df.groupBy(\"contraband_found\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "#Create a new column for contraband_found \n",
    "df = df.withColumn(\"contraband_found_resolved\", when(df.contraband_found == \"NA\", 0).otherwise(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- subject_race: string (nullable = true)\n",
      " |-- subject_sex: string (nullable = true)\n",
      " |-- arrest_made: string (nullable = true)\n",
      " |-- citation_issued: string (nullable = true)\n",
      " |-- warning_issued: string (nullable = true)\n",
      " |-- outcome: string (nullable = true)\n",
      " |-- contraband_found: string (nullable = true)\n",
      " |-- contraband_drugs: string (nullable = true)\n",
      " |-- contraband_weapons: string (nullable = true)\n",
      " |-- contraband_alcohol: string (nullable = true)\n",
      " |-- contraband_other: boolean (nullable = true)\n",
      " |-- frisk_performed: string (nullable = true)\n",
      " |-- search_conducted: string (nullable = true)\n",
      " |-- search_basis: string (nullable = true)\n",
      " |-- reason_for_search: string (nullable = true)\n",
      " |-- reason_for_stop: string (nullable = true)\n",
      " |-- vehicle_make: string (nullable = true)\n",
      " |-- vehicle_model: string (nullable = true)\n",
      " |-- contraband_found_resolved: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+------+\n",
      "|contraband_found_resolved| count|\n",
      "+-------------------------+------+\n",
      "|                        1| 17762|\n",
      "|                        0|462822|\n",
      "+-------------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check newly created column\n",
    "df.groupBy(\"contraband_found_resolved\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- subject_race: string (nullable = true)\n",
      " |-- subject_sex: string (nullable = true)\n",
      " |-- arrest_made: string (nullable = true)\n",
      " |-- citation_issued: string (nullable = true)\n",
      " |-- warning_issued: string (nullable = true)\n",
      " |-- outcome: string (nullable = true)\n",
      " |-- contraband_found: string (nullable = true)\n",
      " |-- contraband_drugs: string (nullable = true)\n",
      " |-- contraband_weapons: string (nullable = true)\n",
      " |-- contraband_alcohol: string (nullable = true)\n",
      " |-- contraband_other: boolean (nullable = true)\n",
      " |-- frisk_performed: string (nullable = true)\n",
      " |-- search_conducted: string (nullable = true)\n",
      " |-- search_basis: string (nullable = true)\n",
      " |-- reason_for_search: string (nullable = true)\n",
      " |-- reason_for_stop: string (nullable = true)\n",
      " |-- vehicle_make: string (nullable = true)\n",
      " |-- vehicle_model: string (nullable = true)\n",
      " |-- contraband_found_resolved: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import to_date, to_utc_timestamp\n",
    "\n",
    "\n",
    "#Creating a date time \n",
    "df = df.select(to_date(df.date).alias('date'), 'zone', 'subject_race', 'subject_sex', 'arrest_made', 'citation_issued'\n",
    "              , 'warning_issued', 'outcome', 'contraband_found', 'contraband_drugs', 'contraband_weapons', 'contraband_alcohol'\n",
    "               , 'contraband_other', 'frisk_performed', 'search_conducted', 'search_basis', 'reason_for_search'\n",
    "               , 'reason_for_stop', 'vehicle_make', 'vehicle_model', 'contraband_found_resolved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- subject_race: string (nullable = true)\n",
      " |-- subject_sex: string (nullable = true)\n",
      " |-- arrest_made: string (nullable = true)\n",
      " |-- citation_issued: string (nullable = true)\n",
      " |-- warning_issued: string (nullable = true)\n",
      " |-- outcome: string (nullable = true)\n",
      " |-- contraband_found: string (nullable = true)\n",
      " |-- contraband_drugs: string (nullable = true)\n",
      " |-- contraband_weapons: string (nullable = true)\n",
      " |-- contraband_alcohol: string (nullable = true)\n",
      " |-- contraband_other: boolean (nullable = true)\n",
      " |-- frisk_performed: string (nullable = true)\n",
      " |-- search_conducted: string (nullable = true)\n",
      " |-- search_basis: string (nullable = true)\n",
      " |-- reason_for_search: string (nullable = true)\n",
      " |-- reason_for_stop: string (nullable = true)\n",
      " |-- vehicle_make: string (nullable = true)\n",
      " |-- vehicle_model: string (nullable = true)\n",
      " |-- contraband_found_resolved: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "| outcome| count|\n",
      "+--------+------+\n",
      "|      NA|  6763|\n",
      "|citation|428378|\n",
      "|  arrest| 16603|\n",
      "| warning| 28840|\n",
      "+--------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check outcome column\n",
    "df.groupBy(\"outcome\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop features linearly dependent\n",
    "df = df.drop('contraband_drugs', 'contraband_weapons', 'contraband_alcohol', 'contraband_other')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- subject_race: string (nullable = true)\n",
      " |-- subject_sex: string (nullable = true)\n",
      " |-- arrest_made: string (nullable = true)\n",
      " |-- citation_issued: string (nullable = true)\n",
      " |-- warning_issued: string (nullable = true)\n",
      " |-- contraband_found: string (nullable = true)\n",
      " |-- frisk_performed: string (nullable = true)\n",
      " |-- search_conducted: string (nullable = true)\n",
      " |-- search_basis: string (nullable = true)\n",
      " |-- reason_for_search: string (nullable = true)\n",
      " |-- reason_for_stop: string (nullable = true)\n",
      " |-- vehicle_make: string (nullable = true)\n",
      " |-- vehicle_model: string (nullable = true)\n",
      " |-- contraband_found_resolved: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop features not known prior to making the stop\n",
    "df = df.drop('arrest_made', 'frisk_performed', 'search_basis', 'reason_for_search', 'reason_for_stop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop features not known prior to making the stop\n",
    "df = df.drop('warning_issued', 'citation_issued')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- subject_race: string (nullable = true)\n",
      " |-- subject_sex: string (nullable = true)\n",
      " |-- contraband_found: string (nullable = true)\n",
      " |-- search_conducted: string (nullable = true)\n",
      " |-- vehicle_make: string (nullable = true)\n",
      " |-- vehicle_model: string (nullable = true)\n",
      " |-- contraband_found_resolved: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|vehicle_make| count|\n",
      "+------------+------+\n",
      "|        MERK|     1|\n",
      "|          PC|     1|\n",
      "|        DODG| 14170|\n",
      "|        MASE|    30|\n",
      "|        PEUG|     1|\n",
      "|        DATS|     7|\n",
      "|        EAGL|     1|\n",
      "|        STLG|    93|\n",
      "|        FRUE|     9|\n",
      "|        LINC|  2659|\n",
      "|        INTE|     1|\n",
      "|        AMER|    15|\n",
      "|        MERZ|  3159|\n",
      "|        TRIM|     1|\n",
      "|        AMGN|    71|\n",
      "|        FIAT|    44|\n",
      "|        ISUZ|     1|\n",
      "|          NA|162525|\n",
      "|        CHRY|  7550|\n",
      "|        TRIU|    18|\n",
      "+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check vehicle make column\n",
    "df.groupBy(\"vehicle_make\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|Distinct vehicle makes|\n",
      "+----------------------+\n",
      "|                    97|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct, avg, stddev\n",
    "df.select(countDistinct(\"vehicle_make\").alias(\"Distinct vehicle makes\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|vehicle_model|count|\n",
      "+-------------+-----+\n",
      "|        ASTRO|   92|\n",
      "|          MDX|  590|\n",
      "|       CHR300|  123|\n",
      "|          BOX|   43|\n",
      "|           LT|    7|\n",
      "|         545I|   30|\n",
      "|      MAZDA3I|    4|\n",
      "|     6 TOURIN|    2|\n",
      "|     LE SABLE|    6|\n",
      "|    GEO PRIZM|    5|\n",
      "|          E.S|    1|\n",
      "|    TL S-TYPE|    1|\n",
      "|          ETK|    1|\n",
      "|     TEMPO GL|    4|\n",
      "|         PROS|    5|\n",
      "|      LLUMINA|    3|\n",
      "|    ENTOURAGE|   14|\n",
      "| LEGACY WAGON|    2|\n",
      "|     6 SERIES|    4|\n",
      "|          ...|   15|\n",
      "+-------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check vehicle model column\n",
    "df.groupBy(\"vehicle_model\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|Distinct vehicle models|\n",
      "+-----------------------+\n",
      "|                   9184|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct, avg, stddev\n",
    "df.select(countDistinct(\"vehicle_model\").alias(\"Distinct vehicle models\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop vehicle model\n",
    "df = df.drop('vehicle_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- subject_race: string (nullable = true)\n",
      " |-- subject_sex: string (nullable = true)\n",
      " |-- contraband_found: string (nullable = true)\n",
      " |-- search_conducted: string (nullable = true)\n",
      " |-- vehicle_make: string (nullable = true)\n",
      " |-- contraband_found_resolved: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|search_conducted| count|\n",
      "+----------------+------+\n",
      "|           FALSE|462822|\n",
      "|            TRUE| 17762|\n",
      "+----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NA Values in some fields\n",
    "df.groupBy(\"search_conducted\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "#Create a new column for contraband_found \n",
    "df = df.withColumn(\"search_conducted\", when(df.search_conducted == \"FALSE\", 0).otherwise(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- subject_race: string (nullable = true)\n",
      " |-- subject_sex: string (nullable = true)\n",
      " |-- contraband_found: string (nullable = true)\n",
      " |-- search_conducted: integer (nullable = false)\n",
      " |-- vehicle_make: string (nullable = true)\n",
      " |-- contraband_found_resolved: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "#Create a new column for contraband_found \n",
    "df = df.withColumn(\"contraband_found\", when(df.contraband_found == \"FALSE\", 0).otherwise(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- date: date (nullable = true)\n",
      " |-- zone: string (nullable = true)\n",
      " |-- subject_race: string (nullable = true)\n",
      " |-- subject_sex: string (nullable = true)\n",
      " |-- contraband_found: integer (nullable = false)\n",
      " |-- search_conducted: integer (nullable = false)\n",
      " |-- vehicle_make: string (nullable = true)\n",
      " |-- contraband_found_resolved: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports for assembler, encoder, indexer\n",
    "from pyspark.ml.feature import (VectorAssembler,VectorIndexer,\n",
    "                                OneHotEncoder,StringIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working with categorical data\n",
    "\n",
    "# First create a string indexer (convert every string into a number, such as male = 0 and female = 1).\n",
    "# A number will be assigned to every category in the column.\n",
    "gender_indexer = StringIndexer(inputCol='subject_sex',outputCol='SexIndex')\n",
    "\n",
    "# Now we can one hot encode these numbers. This converts the various outputs into a single vector.\n",
    "# This makes it easier to process when you have multiple classes.\n",
    "gender_encoder = OneHotEncoder(inputCol='SexIndex',outputCol='SexVec')\n",
    "\n",
    "#Similar to the above.\n",
    "race_indexer = StringIndexer(inputCol='subject_race',outputCol='raceIndex')\n",
    "race_encoder = OneHotEncoder(inputCol='raceIndex',outputCol='raceVec')\n",
    "\n",
    "#Similar to the above.\n",
    "zone_indexer = StringIndexer(inputCol='zone',outputCol='zoneIndex')\n",
    "zone_encoder = OneHotEncoder(inputCol='zoneIndex',outputCol='zoneVec')\n",
    "\n",
    "#Similar to the above.\n",
    "vehicle_indexer = StringIndexer(inputCol='vehicle_make',outputCol='vehicleIndex')\n",
    "vehicle_encoder = OneHotEncoder(inputCol='vehicleIndex',outputCol='vehicleVec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can assemble all of this as one vector in the features column. \n",
    "assembler = VectorAssembler(inputCols=['date', \n",
    " 'SexVec',\n",
    " 'zoneVec',\n",
    " 'search_conducted',\n",
    " 'vehicleVec',                                      \n",
    " 'raceVec'],outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that survived is a categorial variable but didn't require any transformation.\n",
    "# That's because it's already in the format of 1's and 0's. \n",
    "log_reg = LogisticRegression(featuresCol='features',labelCol='contraband_found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists everything we want to do. Index data, encode data, assemble data and then pass in the actual model.\n",
    "pipeline = Pipeline(stages=[gender_indexer,race_indexer, zone_indexer, vehicle_indexer, \n",
    "                           gender_encoder,race_encoder, zone_encoder, vehicle_encoder,\n",
    "                           assembler,log_reg])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split. \n",
    "train_data, test_data = df.randomSplit([0.7,.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Data type DateType is not supported.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o399.transform.\n: java.lang.IllegalArgumentException: Data type DateType is not supported.\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$transformSchema$1.apply(VectorAssembler.scala:121)\n\tat org.apache.spark.ml.feature.VectorAssembler$$anonfun$transformSchema$1.apply(VectorAssembler.scala:117)\n\tat scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)\n\tat scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)\n\tat org.apache.spark.ml.feature.VectorAssembler.transformSchema(VectorAssembler.scala:117)\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\n\tat org.apache.spark.ml.feature.VectorAssembler.transform(VectorAssembler.scala:54)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-73f982ff41a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Note pipeline. Call it as you would call a machine learning object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# must be an Estimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Data type DateType is not supported.'"
     ]
    }
   ],
   "source": [
    "# Note pipeline. Call it as you would call a machine learning object.\n",
    "fit_model = pipeline.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform test data. \n",
    "results = fit_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'my_eval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-338036563e60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#We can then evaluate using AUC (area under the curve). AUC is linked to ROC.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mAUC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mAUC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'my_eval' is not defined"
     ]
    }
   ],
   "source": [
    "#We can then evaluate using AUC (area under the curve). AUC is linked to ROC.\n",
    "AUC = my_eval.evaluate(results)\n",
    "\n",
    "AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
